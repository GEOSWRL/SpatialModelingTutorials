{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EGAM example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN9Uxqke9k1R+s7vuCBjSvM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jshogland/SpatialModelingTutorials/blob/main/Notebooks/EGAM_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMAFw5OTLz78"
      },
      "source": [
        "# R ensemble generalized additive model (EGAM) example\n",
        "## Developed by\n",
        "## John Hogland 5/17/2021\n",
        "### Contact john.s.hogland@usda.gov\n",
        "### Required libraries, mgcv, raster, rgdal, rgeos, gstat, snow\n",
        "\n",
        "This is a working example of the EGAM procedures described in (Hogland et. al. 2018, and Hogland et. al. 2019). These procedures can be broken down into 3 main components: 1) a variable selection routine, 2) a EGAM creation routine, and 3) a raster creation component. To illustrate this routine we will be creating a raster dataset with spatial correlation and predefined error. Let's get started!\n",
        "\n",
        "---\n",
        "\n",
        "Hogland, J.; Anderson, N.; St. Peter, J; Drake, J.; Medley, P. 2018. Mapping forest characteristics at fine resolution across large landscapes of the southeastern United States using NAIP imagery and FIA field plot data, *International journal of Geo-Information*, 7(4): 140. https://www.mdpi.com/2220-9964/7/4/140 \n",
        "\n",
        "Hogland, J.; Affleck, D.L.; Anderson, N.; Seielstad, C.; Dobrowski, S.; Graham, J.; Smith, R. 2020. Estimating forest characteristics for longleaf pine restoration using normalized remotely sensed imagery in Florida, USA. *Forests*, 11, 426. https://www.mdpi.com/1999-4907/11/4/426\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKxQx7as3jS0"
      },
      "source": [
        "# Install required packages and load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM6GlGDqLJGU"
      },
      "source": [
        "\n",
        "install.packages(c(\"rgdal\",\"raster\",\"rgeos\",\"gstat\",\"snow\"))\n",
        "\n",
        "library(rgdal)\n",
        "library(raster)\n",
        "library(rgeos)\n",
        "library(gstat)\n",
        "library(mgcv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1XGVbkgMXPS"
      },
      "source": [
        "# Create a raster dataset with spatial autocorrelation. This surface is made up but for this example it can be thought of as a basal area per acre (BAA; ft squared). \n",
        "\n",
        "\n",
        "1.   Define a new raster size 200 * 200\n",
        "2.   Define the gstat object range, sill, mean\n",
        "3.   Create the gstat model with spherical correlation\n",
        "4.   Use the model to predict raster values\n",
        "5.   Convert grid to a raster object\n",
        "6.   Plot the raster object\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtkvL6b__hkJ"
      },
      "source": [
        "# 1. Define a new raster size 200 *200\n",
        "clm<-200\n",
        "n<-clm*clm\n",
        "xy <- expand.grid(1:clm, 1:clm) #create a grid of x and y locations\n",
        "names(xy) <- c(\"x\",\"y\") #name the columns\n",
        "\n",
        "# 2. define the gstat object range,sill, mean\n",
        "rngVl<-15 # range value for correlogram\n",
        "vr<-250 #variance parameter (sill)\n",
        "mn<-150 #mean value\n",
        "\n",
        "# 3. Create the gstat model  wiht spherical correlation\n",
        "g.dummy <- gstat(formula=z~1, locations=~x+y, dummy=T, beta=c(mn), model=vgm(psill=vr,model=\"Sph\",range=rngVl), nmax=30) #gstat model with spatial correlation\n",
        "\n",
        "# 4. Use the model to predic raster values\n",
        "yy <- predict(g.dummy, newdata=xy,nsim=1)\n",
        "\n",
        "# 5. Convert grid to a raster object\n",
        "gridded(yy) = ~x+y\n",
        "rs1<-raster(yy)\n",
        "\n",
        "# 6. Plot the raster object\n",
        "print(rs1)\n",
        "plot(rs1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFo-jVJVKkdc"
      },
      "source": [
        "# Create three predictor variable raster surfaces that are correlated with our response surface (rs1) and have different types of error.\n",
        "\n",
        "\n",
        "1.   Define a correlative function with error for 3 predictor variables (no additional spatial error).\n",
        "2.   Create error surfaces.\n",
        "3.   Create predictor raster surfaces.\n",
        "4.   Plot raster surfaces\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACtqJb9nL3Af"
      },
      "source": [
        "# 1. Define a correlative Funciton with error for 3 predictor variables (no additoinal spatial error)\n",
        "\n",
        "# predictor 1 formula   p1= 2*rs1 + 10.5*rs1^2 - 0.05*rs1^3 +error(normal)\n",
        "# predictor 2 formula   p2 = 5*ln(rs1) + rs1^2 + error2(poisson)\n",
        "# predictor 3 formula   p3= 2*(rs1)^3 + error3 (normal)\n",
        "\n",
        "#'function to create predictor variables given a raster template, error term, and error type\n",
        "#'@param tmplateRs = template raster\n",
        "#'@param eTerm = the amount of error\n",
        "#'@param errorType = the type of error\n",
        "#'@param return = a raster surface with error\n",
        "createPredSurface = function(tmplateRs, eTerm = \"\", errorType = 'poisson') {\n",
        "    clms = ncol(tmplateRs)\n",
        "    rws = nrow(tmplateRs)\n",
        "    errRs = raster(tmplateRs)\n",
        "    if (errorType == 'normal') {\n",
        "        err = rnorm((rws * clms), 0, eTerm)\n",
        "    } else if (errorType == 'poisson') {\n",
        "        err = rpois(tmplateRs[], tmplateRs[])*0.5 + 0.00001\n",
        "    } else if (errorType == 'proportional') {\n",
        "        err = tmplateRs[] * rnorm((rws * clms), eTerm, eTerm * 0.6)\n",
        "    } else {\n",
        "        err = rnorm((rws * clms), 0, eTerm)\n",
        "    }\n",
        "    errRs[] = err\n",
        "    return(errRs)\n",
        "}\n",
        "\n",
        "# 2. create error surfaces\n",
        "errRs1 = createPredSurface(rs1, 1500, 'normal')\n",
        "errRs2 = createPredSurface(rs1)^2*40\n",
        "errRs3 = createPredSurface(rs1, 0.70, 'proportional') ^3\n",
        "\n",
        "# 3. create predictor rasters surfaces\n",
        "pred1 = 2*rs1 + 10.5*rs1^2 + -0.05*rs1^3 + errRs1\n",
        "pred2 = 5*log(rs1) + rs1^2 + errRs2\n",
        "pred3 = 2*(rs1)^3 + errRs3\n",
        "\n",
        "#set null values to zero (due to forumula)\n",
        "pred1[is.na(pred1)] = 0\n",
        "pred2[is.na(pred2)] = 0\n",
        "pred3[is.na(pred3)] = 0\n",
        "\n",
        "# 4. Plot raster surfaces\n",
        "pred = stack(pred1,pred2,pred3)\n",
        "print(pred)\n",
        "plot(pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0is1gh_jcu9I"
      },
      "source": [
        "# Randomly sample our raster surfaces (response and predictor)\n",
        "\n",
        "\n",
        "1.   Create a random sample of 400 locations\n",
        "2.   Use sample location coordinates to extract raster values\n",
        "3.   Turn those extracted values into a data frame\n",
        "4.   Split that data frame into a training (dft,n=200) and validation (dfv,n=200) datasets\n",
        "4.   View data and relationship for the training sample\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdH7Mz-qc8p3"
      },
      "source": [
        "# 1. Create a random sample of 400 locations\n",
        "obsCnt = ncell(rs1)\n",
        "rspVls = sample(seq(obsCnt),400)\n",
        "\n",
        "# 2. Use the coordinates of that sample location to extract raster values\n",
        "# 3. Turn those extracted values into a data frame\n",
        "dfall = data.frame(resp=rs1[][rspVls],pred1=pred1[][rspVls],pred2=pred2[][rspVls],pred3=pred3[][rspVls])\n",
        "\n",
        "# 4. Split that data frame into a training (dft,n=200) and validation (dfv,n=200) datasets\n",
        "sIndex = sample(nrow(dfall), 200)\n",
        "dft = dfall[sIndex,]\n",
        "dfv = dfall[-sIndex,]\n",
        "\n",
        "# 5. View data and relationship for the training sample\n",
        "head(dft)\n",
        "plot(dft$pred1,dft$resp)\n",
        "plot(dft$pred2,dft$resp)\n",
        "plot(dft$pred3,dft$resp)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWU8l9eSmqG5"
      },
      "source": [
        "# Now that we have a dataset with response and predictors, we can use mgcv to select predictors and generate our EGAM.\n",
        "\n",
        "\n",
        "1.   Create an iterative function to select predictor variables.\n",
        "2.   Get significant variabels using getGamSigFldNames adn the dataframe (dft) and look at model fit statistics and visualization plots.\n",
        "3.   Create ensemble of GAMS (EGAMS) function.\n",
        "4.   Use the CreateEnsembelGam function to make a EGAM with our data frame (dft) and our significant predictor variables (predVar).\n",
        "5.   Report RMSE and graph observed vs predicted values for validation dataset (dfv) with a grey one to one line, smoothed loess line, and red dashed 95% confidence intervals and the approximate 95% prediction intervals (green dashed lines).\n",
        "6.   Apply our model to our predictor raster surfaces to create a new surface with mean and standard error estimates.\n",
        "7.   Compare the response surface to the predicted surface and plot the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cHBaOL3ozq9"
      },
      "source": [
        "# 1. Create an iterative function to select predictor variables. \n",
        "> ### getGamSigFldNames(indata, resp, pred, alpha = 0.05, fam = gaussian(), improveby = 0)\n",
        "> note, running this code will load functions into memory but will not produce output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "432B57-cNRD4"
      },
      "source": [
        "#' Get best GAM using all data in the data framee\n",
        "#' @param indata = input data frame\n",
        "#' @param resp = response field name\n",
        "#' @param pred = vector of potential predictor variables\n",
        "#' @param alpha = significance level used to select variables (0.05)\n",
        "#' @param fam = family distribution (gaussian())\n",
        "#' @param improveby = the amount needed to improve % deviance explained to include a predictor variable (0)\n",
        "#' @return = list of significant variable vector and GAM\n",
        "getGamSigFldNames<-function(indata, resp, pred, alpha = 0.05, fam = gaussian(), improveby = 0) {\n",
        "    nlp = 1\n",
        "    if (fam$family == \"multinom\") {\n",
        "        nlp = fam$nlp\n",
        "    }\n",
        "    sigVar <- c()\n",
        "    pdiv <- 0\n",
        "    pr2 <- 0\n",
        "    for (i in seq(length(pred))) {\n",
        "        vars <- c(sigVar, pred[i])\n",
        "        fm <- getFormula(resp,vars,nlp) \n",
        "        md <- gam(fm, data = indata, family = fam)\n",
        "        smry <- summary(md)\n",
        "        div <- smry$dev.expl\n",
        "        if (div > (pdiv + improveby)) {\n",
        "            print(paste(\"Adding variable\", pred[i], collapse = \" \"))\n",
        "            pvalues <- c(smry$s.pv)\n",
        "            sigVar <- c()\n",
        "            nonSigVar <- c()\n",
        "            for (j in seq(length(vars))) {\n",
        "                pv <- getSmallestPvalue(j,pvalues,nlp)\n",
        "                if (pv <= alpha) {\n",
        "                    sigVar <- c(sigVar, vars[j])\n",
        "                }\n",
        "                else {\n",
        "                    nonSigVar <- c(nonSigVar, vars[j])\n",
        "                }\n",
        "            }\n",
        "            if (length(nonSigVar) > 0) {\n",
        "                for (k in nonSigVar) {\n",
        "                    print(paste(cat(\"\\t\"), \"Rechecking non significant variables\", k, collapse = \" \"))\n",
        "                    vars2 <- c(sigVar, k)\n",
        "                    cfm <- getFormula(resp,vars2,nlp)\n",
        "                    nmd <- gam(cfm, data = indata, family = fam)\n",
        "                    nsmry <- summary(nmd)\n",
        "                    ndiv <- nsmry$dev.expl\n",
        "                    pvalues <- c(nsmry$s.pv)\n",
        "                    cpvalue <- getSmallestPvalue(length(vars2),pvalues,nlp)\n",
        "                    if (cpvalue <= alpha) {\n",
        "                        sigVar <- c(sigVar, k)\n",
        "                        print(paste(cat(\"\\t\"), \"adding\", k, \"back to the model\", collapse = \" \"))\n",
        "                    }\n",
        "                }\n",
        "                ndiv <- pdiv\n",
        "                if (length(sigVar) > 0) {\n",
        "                    cfm <- getFormula(resp,sigVar,nlp) #as.formula(paste(resp, \" ~ \", paste(\"s(\", sigVar, \")\", collapse = \" + \")))\n",
        "                    nmd <- gam(cfm, data = indata, family = fam)\n",
        "                    nsmry <- summary(nmd)\n",
        "                    ndiv <- nsmry$dev.expl\n",
        "                }\n",
        "                if (ndiv < (pdiv + improveby)) {\n",
        "                    print(paste(cat(\"\\t\"), \"No improvement. Changing sig variables back to what they previously were\"))\n",
        "                    sigVar <- vars[1:length(vars) - 1]\n",
        "                }\n",
        "                else {\n",
        "                    pdiv <- ndiv\n",
        "                }\n",
        "            }\n",
        "            else {\n",
        "                pdiv <- div\n",
        "            }\n",
        "            print(paste(cat(\"\\t\"), \"sig var for iter \", i, \"(%Div = \",pdiv, \"):\", paste(sigVar, collapse = \" \")))\n",
        "        }\n",
        "    }\n",
        "    print(paste(cat(\"\\t\"), \"Removing variables that do not meet significance level\",sep = \"\"))\n",
        "    fmd <- removeLeastSignificantVar(resp, indata, sigVar, fam, alpha, nlp)\n",
        "    while (!is.null(fmd[[1]])) {\n",
        "        sigVar = fmd[[1]]\n",
        "        fmd = removeLeastSignificantVar(resp, indata, sigVar, fam, alpha, nlp)\n",
        "    }\n",
        "    return(list(sigVar,fmd[[2]]))\n",
        "}\n",
        "\n",
        "#  Used to remove the least significant variable and make a new GAM.\n",
        "#' @param resp = response field name \n",
        "#' @param indata = input data frame\n",
        "#' @param sigVar = vector of significant variables\n",
        "#' @param fam = family distribution (gaussian())\n",
        "#' @param alpha = significance level used to select variables (0.05)\n",
        "#' @param nlp = the number of linear predictors\n",
        "#' @return = list of significant variable vector and GAM\n",
        "removeLeastSignificantVar <- function(resp, indata, sigVar, fam, alpha, nlp) {\n",
        "    cfm <- getFormula(resp, sigVar, nlp)\n",
        "    nmd <- gam(cfm, data = indata, family = fam)\n",
        "    nsmry <- summary(nmd)\n",
        "    pvalues <- c(nsmry$s.pv)\n",
        "    fVar <- c()\n",
        "    malpha = NULL\n",
        "    nSigVar = NULL\n",
        "    for (i in 1:length(sigVar)) {\n",
        "        tpv <- getSmallestPvalue(i, pvalues, nlp)\n",
        "        fVar <- c(fVar,tpv)\n",
        "    }\n",
        "    fVarT = fVar > alpha\n",
        "    if (sum(fVarT) > 0) {\n",
        "        malpha = max(fVar)\n",
        "    }\n",
        "    if (!is.null(malpha)) {\n",
        "        mVarIndex = which(fVar == malpha)\n",
        "        nSigVar = sigVar[-mVarIndex]\n",
        "    }\n",
        "    \n",
        "    return(list(nSigVar,nmd))\n",
        "}\n",
        "\n",
        "#  Used to get the preditor with the smallest p value.\n",
        "#' @param vlIndex = index of variable\n",
        "#' @param pvalues = vector of pvalues\n",
        "#' @param nlp = number of linear predictors\n",
        "#' @return = smallest pvalue\n",
        "getSmallestPvalue <- function(vlIndex, pvalues, nlp) {\n",
        "    mVl = pvalues[vlIndex]\n",
        "    if (nlp > 1) {\n",
        "        cVec <- vector(mode = \"numeric\", length = nlp)\n",
        "        cnt = 1\n",
        "        for (i in seq(vlIndex, length(pvalues), length(pvalues)/nlp)) {\n",
        "            pvl = pvalues[[i]]\n",
        "            cVec[cnt] = pvl\n",
        "            cnt = cnt + 1\n",
        "        }\n",
        "        mVl = min(cVec)\n",
        "    }\n",
        "    return(mVl)\n",
        "}\n",
        "\n",
        "#  Used to create a formula for the mgcv routine.\n",
        "#' @param rVar = response variable\n",
        "#' @param pVars = vector of predictor variables\n",
        "#' @param numlp = number of linear predictors\n",
        "#' @return = formula\n",
        "getFormula <- function(rVar, pVars, numlp) {\n",
        "    fm=as.formula(paste(rVar, \" ~ \", paste(\"s(\", pVars, \")\", collapse = \" + \")))\n",
        "    if (numlp > 1) {\n",
        "        fml = list(length = numlp)\n",
        "        fml[[1]] = fm\n",
        "        for (f in 2:numlp) {\n",
        "            fml[[f]] = as.formula(paste(\"~ \", paste(\"s(\", pVars, \")\", collapse = \" + \")))\n",
        "        }\n",
        "        fm <- fml\n",
        "    }\n",
        "    return(fm)\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5dX-aZWpkAS"
      },
      "source": [
        "# 2. Get significant variabels using getGamSigFldNames and the dataframe (dft) and look at model fit statistics and visualization plots.\n",
        "- response = \"resp\"\n",
        "- pred = c(\"pred1\", \"pred2\", \"pred3\")\n",
        "- data frame = dft\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKLf4iq4phfW"
      },
      "source": [
        "outVar=getGamSigFldNames(dft,\"resp\",c(\"pred1\",\"pred2\",\"pred3\"))\n",
        "predVar=outVar[[1]]\n",
        "gamMdl=outVar[[2]]\n",
        "print(predVar)\n",
        "summary(gamMdl)\n",
        "plot(gamMdl)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCa4qeQOFQbm"
      },
      "source": [
        "# 3. Create ensemble of GAMS (EGAMS) function \n",
        "> ### createEnsembleGam(frm, df, fam, nmdl, ptrain, kfact)\n",
        "> ### predictEnsembleGam(bGamMdl, df)\n",
        "> note, running this code will load functions into memory but will not produce output\n",
        "\n",
        "1.   Create a generic ensemble function\n",
        "2.   Create 3 helper functions that get called within the createEnembleGam function\n",
        "3.   Create a EGAM prediction function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl1j0vVkrm3Y"
      },
      "source": [
        "#1. Create a generic ensemble function\n",
        "\n",
        "#' This function creates an EGAM\n",
        "#' @param frm = formula\n",
        "#' @param df = dataframe\n",
        "#' @param fam = family default = gaussian()\n",
        "#' @param nmdl = number of models default = 50\n",
        "#' @param ptrain = percent of data used to train the model default = 0.75\n",
        "#' @param kfact = keep factor for models: used to select models that have a similar RMSE training and testing datasets\n",
        "#' @return list of gam models, oob, and training rmse\n",
        "createEnsembleGam <- function(frm, df, fam = gaussian(), nmdl = 50, ptrain = 0.75, kfact = 20) {\n",
        "    mdlV = list(length = nmdl)\n",
        "    rmseV = vector(mode = \"double\", length = nmdl)\n",
        "    rmseT = vector(mode = \"double\", length = nmdl)\n",
        "    n = round(ptrain * nrow(df))\n",
        "    mdlCnt = 0\n",
        "    while (mdlCnt < nmdl) {\n",
        "        sIndex = sample(nrow(df), n)\n",
        "        tdf = df[sIndex,]\n",
        "        vdf = df[-sIndex,]\n",
        "        try({\n",
        "            mdl = gam(frm, family = fam, data = tdf)\n",
        "\n",
        "            pvlV = getPredictedValues(mdl, vdf) \n",
        "            ovlV = getResponseValues(vdf, mdl) \n",
        "            t_rmseV = getErrorEstimate(pvlV, ovlV, mdl) \n",
        "\n",
        "            pvlT = getPredictedValues(mdl, tdf) \n",
        "            ovlT = getResponseValues(tdf, mdl) \n",
        "            t_rmseT = getErrorEstimate(pvlT, ovlT, mdl)\n",
        "\n",
        "            if (t_rmseV <= (t_rmseT * kfact)) {\n",
        "                mdlCnt = mdlCnt + 1\n",
        "                mdlV[[mdlCnt]] = mdl\n",
        "                rmseV[mdlCnt] = t_rmseV\n",
        "                rmseT[mdlCnt] = t_rmseT\n",
        "            }\n",
        "        }, silent = TRUE)\n",
        "    }\n",
        "    return(list(mdlV, rmseV, rmseT))\n",
        "}\n",
        "\n",
        "# 2. Create 3 helper functions that get called within the createEnembleGam function\n",
        "\n",
        "#' Gets the predicted values from the model\n",
        "#' md = gam model\n",
        "#' df = dataframe\n",
        "#' t = type of prediction (default = \"response\")\n",
        "getPredictedValues <- function(md, df, t = \"response\") {\n",
        "    pVls = predict(md, newdata = df, type = t)\n",
        "    fm = md$family\n",
        "    if (fm$family == \"multinom\") {\n",
        "        pVls <- apply(pVls, 1, function(x) which(max(x) == x)[1]) - 1\n",
        "    }\n",
        "    if (fm$family == \"binomial\") {\n",
        "        pVls <- as.integer(pVls > 0.5)\n",
        "    }\n",
        "    return(pVls)\n",
        "}\n",
        "\n",
        "#' Gets the response values from a GAM model given a dataframe\n",
        "#' df = dataframe\n",
        "#' md = GAM\n",
        "getResponseValues <- function(df, md) {\n",
        "    fm = md$family\n",
        "    f = md$formula\n",
        "    if (fm$family == \"multinom\") {\n",
        "        f = f[[1]]\n",
        "    }\n",
        "    return(df[all.vars(f)[1]][[1]])\n",
        "}\n",
        "\n",
        "#' Gets error estimates from a GAM\n",
        "#' p = predicted values \n",
        "#' o = observed values\n",
        "#' md = GAM\n",
        "getErrorEstimate <- function(p, o, md) {\n",
        "    fm = md$family\n",
        "    outVl = NULL\n",
        "    if (fm$family == \"multinom\" | fm$family == \"binomial\") {\n",
        "        outVl = 1 - sum(p == o) / length(p)\n",
        "    }\n",
        "    else {\n",
        "        outVl = sqrt(mean((p - o) ^ 2))\n",
        "    }\n",
        "    return(outVl)\n",
        "}\n",
        "\n",
        "# 3. Create a EGAM prediction function\n",
        "\n",
        "#' Predict EGAM model values\n",
        "#' @param bGamMdl = list of models\n",
        "#' @param df = new data dataframe\n",
        "#' @return = vector of mean predictions and standard errors\n",
        "predictEnsembleGam <- function(bGamMdl, df) {\n",
        "    fm = bGamMdl[[1]]$family\n",
        "    m = NULL\n",
        "    s = NULL\n",
        "    mdls = length(bGamMdl)\n",
        "    n = nrow(df)\n",
        "    if (fm$family == \"multinom\") {\n",
        "        nlp = fm$nlp\n",
        "        sm = matrix(rep(0, n * (nlp + 1)), nrow = n, ncol = nlp + 1)\n",
        "        s2m = sm\n",
        "        for (i in seq(mdls)) {\n",
        "            mdl = bGamMdl[[i]]\n",
        "            p = predict(mdl, df, type = \"response\")\n",
        "            sm = sm + p\n",
        "            s2m = s2m + p ^ 2\n",
        "        }\n",
        "        m = sm / mdls\n",
        "        s = sqrt((s2m - ((sm ^ 2) / mdls)) / (mdls - 1))\n",
        "        return(cbind(m, s))\n",
        "\n",
        "    }\n",
        "    else {\n",
        "        sV = vector(mode = \"double\", length = n)\n",
        "        s2V = vector(mode = \"double\", length = n)\n",
        "        for (i in seq(mdls)) {\n",
        "            mdl = bGamMdl[[i]]\n",
        "            p = predict(mdl, df, type = \"response\")\n",
        "            sV = sV + p\n",
        "            s2V = s2V + p ^ 2\n",
        "        }\n",
        "        m = sV / mdls\n",
        "        s = sqrt((s2V - ((sV ^ 2) / mdls)) / (mdls - 1))\n",
        "        return(cbind(m, s))\n",
        "    }\n",
        "\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twuBHvqW3RK5"
      },
      "source": [
        "# 4. Use the CreateEnsembelGam function to make a EGAM with our data frame (dft) and our significant predictor variables (predVar).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5WmAkBx4wDM"
      },
      "source": [
        "frm1=getFormula(\"resp\",predVar,1)\n",
        "egamOut = createEnsembleGam(frm1,dft,nmdl=50,ptrain=0.7,kfact=30)\n",
        "egam=egamOut[[1]]\n",
        "trainError=egamOut[[3]]\n",
        "testError=egamOut[[2]]\n",
        "print(paste(\"Training RMSE = \",mean(trainError),sep=\"\"))\n",
        "print(paste(\"Testing RMSE = \", mean(testError), sep=\"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVB-ohr9DynH"
      },
      "source": [
        "# 5. Report RMSE and graph observed vs predicted values for validation dataset (dfv) with a grey one to one line, smoothed loess line, and red dashed 95% confidence intervals and the approximate 95% prediction intervals (green dashed lines)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVSRWNQ8D-3q"
      },
      "source": [
        "vls = data.frame(predictEnsembleGam(egam,dfv))\n",
        "rmse=sqrt(mean((dfv$resp-vls$m)^2))\n",
        "lims = c(min(dfv$resp),max(dfv$resp))\n",
        "plot(vls$m,dfv$resp,xlim=lims, ylim=lims, xlab=\"Predicted\", ylab=\"Observed\", main=paste(\"RMSE = \", rmse, sep=\"\"))\n",
        "abline(0,1,col=\"grey\",lwd=1)\n",
        "lb = vls$m-(1.96*vls$s)\n",
        "ub = vls$m+(1.96*vls$s)\n",
        "plb = vls$m-(vls$s*sqrt(50)*1.96)\n",
        "pub = vls$m+(vls$s*sqrt(50)*1.96)\n",
        "lines(loess.smooth(vls$m,dfv$resp), col=\"blue\",lwd=1)\n",
        "lines(loess.smooth(lb,dfv$resp),col=\"red\",lty=2,lwd=1)\n",
        "lines(loess.smooth(ub,dfv$resp),col=\"red\",lty=2,lwd=1)\n",
        "lines(loess.smooth(plb,dfv$resp),col=\"green\",lty=2,lwd=1)\n",
        "lines(loess.smooth(pub,dfv$resp),col=\"green\",lty=2,lwd=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrI8fI2aqIgW"
      },
      "source": [
        "# 6. Apply our model to our predictor raster surfaces to create a new surface with mean and standard error estimates\n",
        "\n",
        "\n",
        "1.   Create a raster stack of predictors and rename the predictor raster bands to pred1, pred2, pred3  \n",
        "2.   Run the EGAM prediction function in parallel\n",
        "3.   Plot the results (mean and standard error estimates)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "714QLuXFny_K"
      },
      "source": [
        "library(parallel)\n",
        "# 1. Create a raster stack of predictors and rename the predictor raster bands to pred1, pred2, pred3\n",
        "predRs = stack(pred1,pred2,pred3)\n",
        "names(predRs) = c(\"pred1\",\"pred2\",\"pred3\")\n",
        "\n",
        "# 2. Run the EGAM prediction function in parallel\n",
        "beginCluster(2)\n",
        "baaRs = clusterR(predRs, predict, args = list(model = egam, fun = predictEnsembleGam, index = 1:2), verbose = TRUE, datatype = \"FLT4S\", NAFlag = -9999, progress = 'text')\n",
        "endCluster()\n",
        "\n",
        "# 3. Plot the results (mean and standard error estimates)\n",
        "plot(baaRs[[1]],main=\"Mean Estimate\")\n",
        "plot(baaRs[[2]], main = \"Standard Error Estimates\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-1XPAH2t955"
      },
      "source": [
        "# 7. Compare the response surface to the predicted surface and plot the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLpV5kP2uI2Y"
      },
      "source": [
        "diff = rs1-baaRs[[1]]\n",
        "diffSq = diff^2\n",
        "mse=cellStats(diffSq,\"mean\")\n",
        "rmse=sqrt(mse)\n",
        "plot(diff, main=\"Difference between observed and predictied\", sub=paste(\"RMSE = \",rmse,sep=\"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdbm5hcYWh60"
      },
      "source": [
        "# This ends the EGAM example. "
      ]
    }
  ]
}