{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa1cd96-961e-44fd-a53a-cc0c7546f494",
   "metadata": {},
   "source": [
    "# Machine learning and spatail modeling using raster_tools\n",
    "Author John Hogland 3/29/2022\n",
    "\n",
    "In this example we will use the stands of Apalachicola National Forest (ANF) and raster_tools to create spatial metrics, subset data into a training and validation dataset, create a predictive model, evaluate our model, and apply that model to the population of stands.  \n",
    "\n",
    "## Installing raster_tools and update libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9928872-29a3-4133-b77d-668942be99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade gdown\n",
    "#!pip install --upgrade numba\n",
    "#!pip install --upgrade geopandas\n",
    "#!pip install mapclassify\n",
    "#!pip install --upgrade folium\n",
    "#!pip install raster_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a902f-f6ce-4cb0-852e-a05a51310e35",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "These data consist of one polygon layer (ANFStands.shp) depicting the forested stands of ANF. \n",
    "Fields within the polygon layer include:\n",
    "1. POLY_ID: row id\n",
    "2. EV_CODE: environmental code\n",
    "3. Forest_T_1: forest type 1\n",
    "4. Class: vegetative class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd663688-3daa-46e9-a28a-811dfa2cd14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown, zipfile\n",
    "\n",
    "# url='https://drive.google.com/file/d/1zdiNMH0fopnkvZ2HmnI2ZaP1zIUB68VR/view?usp=sharing'\n",
    "# outfl= r'./ANF_Notebook_data.zip'\n",
    "# gdown.download(url=url,output=outfl,quiet=False,fuzzy=True)\n",
    "\n",
    "# with zipfile.ZipFile(outfl, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee83131c-2246-43e3-b1be-20a779ff67ba",
   "metadata": {},
   "source": [
    "## Import raster_tools and geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13650b3-d8cf-4096-95a0-62778107c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raster_tools import open_vectors, Vector\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebaad68-dcda-4b98-94ae-0f00142c16f1",
   "metadata": {},
   "source": [
    "## Specify path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b16fc-b0a0-4628-8696-3a8990e5d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "anf_path = './ANFStands.shp'\n",
    "anf_df=open_vectors(anf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e98dfb-5811-4db7-9565-82cb0db1bba4",
   "metadata": {},
   "source": [
    "## Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6404c-22ec-4ad3-86f3-418b4dfc66f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Field Names = \" + str(anf_df.field_names))\n",
    "print(\"Projectoin Code = \" + str(anf_df.crs))\n",
    "print(\"ANF Stand Acres\")\n",
    "p1=anf_df.data.compute().plot(column='ACRES',legend=True,figsize=(14,8))\n",
    "p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9fe72-311f-4e77-817d-a4a957473e4f",
   "metadata": {},
   "source": [
    "## Create an interactive map and explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44154d53-c1a9-4913-9676-1dbc92d0fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "#add our layers to the map\n",
    "p1=anf_df.geometry.representative_point().compute().explore(color=\"red\",name=\"Centroid\")\n",
    "p2=anf_df.geometry.compute().explore(m=p1,color=\"blue\",name=\"ANF Stands\")\n",
    "\n",
    "#add ESRI's tiled imagery to potential base maps\n",
    "folium.TileLayer(\n",
    "        tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "        attr = 'Esri',\n",
    "        name = 'Esri Imagery',\n",
    "        overlay = False,\n",
    "        control = True\n",
    "       ).add_to(p2)\n",
    "\n",
    "#add layer controls to the map\n",
    "folium.LayerControl().add_to(p2)\n",
    "\n",
    "#show the interactive map\n",
    "p2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c74751-76d1-4fda-b645-a0111dfe6e9f",
   "metadata": {},
   "source": [
    "## Create a series of functions that quatify shape complexity and that can be used to create predictor variables\n",
    "- _redistribute_vertices\n",
    "- calc_metrics\n",
    "- calc_all \n",
    "- stat_type class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bef50d-4927-4d77-81fe-a68516356c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "from shapely.geometry import MultiPoint, LineString\n",
    "import numpy as np\n",
    "\n",
    "def _redistribute_vertices(geom, distance):\n",
    "    if geom.geom_type == 'LineString':\n",
    "        num_vert = int(round(geom.length / distance))\n",
    "        if num_vert == 0:\n",
    "            num_vert = 1\n",
    "        return LineString(\n",
    "            [geom.interpolate(float(n) / num_vert, normalized=True)\n",
    "             for n in range(num_vert + 1)])\n",
    "    elif geom.geom_type == 'MultiLineString':\n",
    "        parts = [redistribute_vertices(part, distance)\n",
    "                 for part in geom]\n",
    "        return type(geom)([p for p in parts if not p.is_empty])\n",
    "    else:\n",
    "        raise ValueError('unhandled geometry %s', (geom.geom_type,))\n",
    "\n",
    "def calc_metrics(gdf,mtype=8,smp=30):\n",
    "    '''CalcMetric will calculate various spatial shape metrics for a given polygon\n",
    "    gdf: geodataframe with polygon geometry\n",
    "    mtype: statistic type (mean, var, sd, min, max, area, perimeter, perimeter to area, fractal, all) [0,1,2,3,4,5,6,7,8]\n",
    "    \n",
    "    returns: list of values for each row. If all is specified for mtype a list of shape metric value lists will be returned\n",
    "    [[mean], [var], [sd], [min], [max], [area], [perimeter], [perimeter to area], [fractal]]\n",
    "    '''\n",
    "    geo=gdf.geometry\n",
    "    outlst = []\n",
    "    if(mtype==0):\n",
    "        outlst=_calc_all(geo)[0]\n",
    "    elif(mtype==1):\n",
    "        outlst=_calc_all(geo)[1]\n",
    "    elif(mtype==2):\n",
    "        outlst=_cal_all(geo)[2]\n",
    "    elif(mtype==3):\n",
    "        outlst=_calc_all(geo)[3]\n",
    "    elif(mtype==4):\n",
    "        outlst=_calc_all(geo)[4]\n",
    "    elif(mtype==5):\n",
    "        outlst=_calc_all(geo)[5]\n",
    "    elif(mtype==6):\n",
    "        outlst=_calc_all(geo)[6]\n",
    "    elif(mtype==7):\n",
    "        outlst=_calc_all(geo)[7]\n",
    "    elif(mtype==7):\n",
    "        outlst=_calc_all(geo)[8]\n",
    "    else:\n",
    "        outlst=_calc_all(geo,smp)\n",
    "    \n",
    "    return outlst\n",
    "        \n",
    "def _calc_all(geo,smp=30):\n",
    "    outlst=[[],[],[],[],[],[],[],[],[]]\n",
    "    for g in geo.geometry:\n",
    "        c_p = g.representative_point()\n",
    "        lns=LineString(g.exterior.coords)\n",
    "        if(smp!=None):\n",
    "            lns=_redistribute_vertices(lns, smp)\n",
    "        bnd_pnt = MultiPoint(lns.coords)\n",
    "        min= np.inf\n",
    "        max=0\n",
    "        s=0\n",
    "        ss=0\n",
    "        n=0\n",
    "        \n",
    "        for p in bnd_pnt.geoms:\n",
    "            d=c_p.distance(p)\n",
    "            if(d>max):max=d\n",
    "            if(d<min):min=d\n",
    "            s+=d\n",
    "            ss+=d*d\n",
    "            n+=1\n",
    "        outlst[0].append(s/n)\n",
    "        var=(ss - ((s*s)/n))/(n-1)\n",
    "        outlst[1].append(var)\n",
    "        outlst[2].append(np.sqrt(var))\n",
    "        outlst[3].append(min)\n",
    "        outlst[4].append(max)\n",
    "        a=g.area\n",
    "        p=g.length\n",
    "        outlst[5].append(a)\n",
    "        outlst[6].append(p)\n",
    "        outlst[7].append(p/a)\n",
    "        outlst[8].append(np.log(a)/(np.log(p)+np.log(0.25)))\n",
    "    \n",
    "    return outlst\n",
    "\n",
    "class stat_type():\n",
    "    '''shape metrices'''\n",
    "    MEAN = 0\n",
    "    VAR = 1\n",
    "    SD = 2\n",
    "    MIN = 3\n",
    "    MAX = 4\n",
    "    AREA = 5\n",
    "    PERIMETER = 6\n",
    "    PA = 7\n",
    "    FRACTAL= 8\n",
    "    ALL = 9\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f56e21-9b5c-4601-9a6a-778c683fd3c5",
   "metadata": {},
   "source": [
    "## Look at the centroid, polygon boundary, vertices, and shape metrics for the first geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec7b62-2eae-4cdd-8060-48effde4814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiPoint, MultiLineString, LineString, Point\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "geo=anf_df.geometry[0].compute()\n",
    "cp=geo.representative_point()\n",
    "bndy=geo.boundary\n",
    "p1=bndy.plot(figsize=(10,15))\n",
    "p2=cp.plot(ax=p1,color='red',markersize=40)\n",
    "p3=gpd.GeoSeries(Point(pnt[0],pnt[1]) for pnt in list(bndy[0].coords)).plot(ax=p2,color='blue',markersize=20)\n",
    "print(_calc_all(geo,None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52936c76-d607-4ef6-8850-f31c2dc008eb",
   "metadata": {},
   "source": [
    "## Look at centroid, polygon boundary, vertices, and shape metrics for the first geometry densified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98221a5a-4201-4715-8bd2-2086b2239a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nbndy=gpd.GeoSeries(_redistribute_vertices(LineString(bndy[0]),100))\n",
    "p1=nbndy.plot(figsize=(10,15))\n",
    "p2=cp.plot(ax=p1,color='red',markersize=40)\n",
    "p3=gpd.GeoSeries(Point(pnt[0],pnt[1]) for pnt in list(nbndy[0].coords)).plot(ax=p2,color='blue',markersize=20)\n",
    "print(_calc_all(geo,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25baa40-95e0-434f-b278-384373da3450",
   "metadata": {},
   "source": [
    "## Calculate shape metrics for all geometries densified 100 m \n",
    "- Shape metrics calculated: mean, var, sd, min, max, area, peremiter,peremiter to area, fractal. \n",
    "- This will take a little time to process the data (about 5 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c325401-ba02-48c7-887e-abb0210a1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "vls=calc_metrics(anf_df,mtype=stat_type.ALL,smp=30)\n",
    "#should be a length of 9, 9 listsl\n",
    "print(len(vls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5186a5-7f67-44f9-baa2-877bef670a81",
   "metadata": {},
   "source": [
    "## Add the shape metrics to the dask geopandas dataframe and create a new Vector object\n",
    "- The output from calc_metrics function returns a list of shape metric lists. \n",
    "- Lists correspond to mean (0), var (1), sd (2), min (3), max (4), area (5), perimeter (6), perimeter to area (7), and fractal (8) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9463744-78b2-4fd0-9e01-137f7cea75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "anf_df2=Vector(anf_df.data.assign(Mean=pd.Series(vls[0]),\n",
    "                   Var=pd.Series(vls[1]),\n",
    "                   Sd=pd.Series(vls[2]),\n",
    "                   Min=pd.Series(vls[3]),\n",
    "                   Max=pd.Series(vls[4]),\n",
    "                   Area=pd.Series(vls[5]),\n",
    "                   Pr=pd.Series(vls[6]),\n",
    "                   Pa=pd.Series(vls[7]),\n",
    "                   Fractal=pd.Series(vls[8])\n",
    "                                 )\n",
    "              )\n",
    "anf_df2.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8199e217-8e06-41cf-b999-41900cd6f412",
   "metadata": {},
   "source": [
    "## Split the data into random subsets used to train a model, test a model, and finally validate a model\n",
    "- train sample size 5%\n",
    "- test sample size 5%\n",
    "- validation sample size 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba695733-f043-4e76-ab67-48cfc7112681",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=anf_df2.data.sample(frac=0.10,random_state=12345)\n",
    "train=sub.sample(frac=0.5,random_state=12345)\n",
    "tid=train['POLY_ID']\n",
    "sid=sub['POLY_ID']\n",
    "check=sid.ne(tid)\n",
    "test=sub[check]\n",
    "did=anf_df2.data['POLY_ID']\n",
    "check2=did.ne(sid)\n",
    "val=anf_df2.data[check2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c7338f-41cb-4789-b95e-c71591a46307",
   "metadata": {},
   "source": [
    "## Create random forest functions using scikit learn\n",
    "- random forest model\n",
    "- store model\n",
    "- open model\n",
    "- predict new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9902a46-4532-4818-a82b-710d7fe830f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "def rand_forest(train,resp,pred,trees=50,criterion='gini',n_jobs=-1,max_samples=0.66):\n",
    "    '''This function is used to create a random forest model. \n",
    "    vector: vector object\n",
    "    resp: response column name (string)\n",
    "    pred: list of predictor varible column names (strings)\n",
    "    trees: number of random forest trees\n",
    "    criterion: gini or entropy\n",
    "    n_jobs: number of processors to use when estimating the model (-1 = all)\n",
    "    max_samples: proportion of input data to use to train each tree. 1-max_samples is used to evaluate each tree.\n",
    "    \n",
    "    returns a sklearn random forest model\n",
    "    '''\n",
    "    X = train[pred].to_dask_array().compute()\n",
    "    fct=train[resp].compute().factorize()\n",
    "    y = fct[0]\n",
    "    mdl = RandomForestClassifier(n_estimators=trees,oob_score=True,random_state=0,criterion=criterion,n_jobs=n_jobs,max_samples=max_samples)\n",
    "    mdl.fit(X,y)\n",
    "    return [fct,mdl]   \n",
    "\n",
    "def store_model(mdl,path):\n",
    "    '''This function will serialize a model to disk\n",
    "    inputs include a model (mdl) and a file path with extension (path)\n",
    "   \n",
    "    mdl: sklearn mdl\n",
    "    path: the location to store the model\n",
    "    '''\n",
    "    s = pickle.dump(mdl,open(path, 'wb'))\n",
    "\n",
    "def open_model(path):\n",
    "    '''This function will read a serialized model (path) back into memory\n",
    "    returns model.\n",
    "    \n",
    "    path: the path to the stored model\n",
    "    \n",
    "    returns: scklearn model\n",
    "    '''\n",
    "    mdl = pickle.load(open(path, 'rb'))\n",
    "    return mdl\n",
    "  \n",
    "def predict_new_values(mdl, dgdf, pred):\n",
    "    '''This function will predict the probability of each class for a new record from a random forest model (mdl) and predictor (pred) values \n",
    "    mdl: sklearn random forest model\n",
    "    df: dataframe\n",
    "    pred: predictor values [[0,0,0,0...]]\n",
    "    returns list of class and probabilities, most likely class is located at [0]'''\n",
    "    x=dgdf[pred].to_dask_array().compute()\n",
    "    prb = mdl.predict_proba(x)\n",
    "    return prb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeec571-c4be-4483-9d2c-db1c5f95feca",
   "metadata": {},
   "source": [
    "## Create Random forest model using our training dataset\n",
    "- create the model (mdl)\n",
    "- store the model (anf_veg_class.mdl)\n",
    "- open the model (mdl2)\n",
    "- look at OOBs (mdl, mdl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda59f9-4d0a-4df2-a85c-62cf4e5c7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=['Mean','Sd','Min','Max','Area','Pr','Pa','Fractal']\n",
    "resp='Class'\n",
    "fct,mdl=rand_forest(train,resp,pred)\n",
    "mdl_path='anf_veg_class.mdl'\n",
    "store_model(mdl,mdl_path)\n",
    "mdl2=open_model(mdl_path)\n",
    "print('OOB from mdl = ' + str(mdl.oob_score_))\n",
    "print('OOB from mdl2 = ' + str(mdl2.oob_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a80eb6f-b285-4284-92ab-3a8ae4975d34",
   "metadata": {},
   "source": [
    "## Predict classs probabilities and calculate accuracy for the following datasets:\n",
    "- test\n",
    "- val\n",
    "- anf_df.data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f344a168-5d46-436f-a313-0891981d55e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimation_dataframe(mdl,df,pred,clm_names):\n",
    "    vls=predict_new_values(mdl,df,pred)\n",
    "    odf=gpd.GeoDataFrame(data=vls)\n",
    "    odf.columns = clm_names\n",
    "    odf['MLC']=odf.idxmax(axis=1)\n",
    "    odf['Class']=df['Class'].compute().values\n",
    "    odf['Correct']=odf['MLC'].eq(odf['Class'])\n",
    "    print('Accuracy = ' + str(odf['Correct'].sum()/odf.shape[0]))\n",
    "    return odf\n",
    "\n",
    "est_t=get_estimation_dataframe(mdl,test,pred,fct[1])\n",
    "est_v=get_estimation_dataframe(mdl,val,pred,fct[1])\n",
    "est_all=get_estimation_dataframe(mdl,anf_df2.data,pred,fct[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea52c77f-254a-40db-90ca-9749eea6a0ef",
   "metadata": {},
   "source": [
    "## Graph importance values for predictor variablesPODs presentation to NISC/WFLC task team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2feb83e-7635-4e85-9a91-e4ba1f32a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp=mdl.feature_importances_\n",
    "v_imp = pd.Series(imp, index=pred)\n",
    "fig, ax = plt.subplots(figsize=(14,8))\n",
    "std = np.std([tree.feature_importances_ for tree in mdl.estimators_], axis=0)\n",
    "v_imp.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f59f103-41c4-41cb-9239-29f8d347e37d",
   "metadata": {},
   "source": [
    "## Graph accuracy by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf374f-eb8e-490a-86fd-f03267267a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class by Mapped Values\n",
    "bvl=est_all['Correct'].astype('int').values\n",
    "print(\"Overall Accuracy = \" + str(np.round(bvl.sum()/len(bvl)*100,decimals=2))+ '\\n')\n",
    "mvl=est_all['MLC'].values\n",
    "cvl=est_all['Class'].values\n",
    "xtbl=pd.crosstab(cvl,mvl,dropna=False)\n",
    "print(xtbl)\n",
    "print()\n",
    "xtbl.plot(kind='bar',title=\"MLC (col-0) vs Class (row_0)\",figsize=(15,10),xlabel='Class',ylabel='Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a998a5e-0e9e-4e63-a925-dceb8749c12c",
   "metadata": {},
   "source": [
    "## Merge est_all with anf_df2 and plot Pine class probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117cf5b-0e30-4aa5-af50-e9e1c330649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anf_df3=anf_df2.data.merge(est_all[['Pine','Hardwood','Pine Hardwood','Hardwood Pine','Non Forest','MLC']]).compute()\n",
    "f, axes = plt.subplots(figsize=(20, 10), ncols=2, nrows=4,tight_layout=True)\n",
    "cnt=0\n",
    "for x in pred:\n",
    "    anf_df3.plot(x=x,y='Pine',kind='scatter',ax=axes[cnt//2][cnt%2],)\n",
    "    cnt+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b13de3-614f-4c09-98b3-97c0b0257400",
   "metadata": {},
   "source": [
    "## Explore MLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa8073-e654-41f8-a6dc-c89189a24257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from folium import plugins\n",
    "p1=anf_df3.explore(color=\"red\",name=\"MLC\",column='MLC',style_kwds={'opacity':0.7})\n",
    "\n",
    "#add ESRI's tiled imagery to potential base maps\n",
    "folium.TileLayer(\n",
    "        tiles = 'https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "        attr = 'Esri',\n",
    "        name = 'Esri Imagery',\n",
    "        overlay = False,\n",
    "        control = True\n",
    "       ).add_to(p1)\n",
    "\n",
    "#add layer controls to the map\n",
    "folium.LayerControl().add_to(p1)\n",
    "\n",
    "#add full screen to map\n",
    "plugins.Fullscreen().add_to(p1)\n",
    "\n",
    "#show the interactive map\n",
    "p1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a05d5-4e20-43fe-93d1-dc488886b3a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save to HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9bbe68-7a70-4168-8326-d0b06dcc3067",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.save('mlc.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
